{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamiltonian Monte Carlo algorithm\n",
    "\n",
    "In this notebook, I shall implement Hamiltonian Monte Carlo algorithm (HMC), a MCMC algorithm using Hamiltonian dynamics to propose a point, which is distant from the current point yet with low rejection probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Theory\n",
    "\n",
    "## 1.1 Setting\n",
    "\n",
    "* Let us assume that the variable of interest resides in $\\mathbb{R}^d$, with $d \\in \\mathbb{N}$ being the dimension. \n",
    "* Let $\\pi_Q$ be a probability distribution over $\\mathbb{R}^d$, from which we want to sample. It is assumed that $\\pi_Q$ can be expressed as $\\pi_Q = \\frac{1}{Z_Q} \\tilde{\\pi}_Q$ with constant $Z_Q$ and a unnormalized distribution $\\tilde{\\pi}_Q$, where $\\tilde{\\pi}_Q$ can be evaluated easily.\n",
    "* Let us define $U(q) := - \\log \\tilde{\\pi}_Q(q)$, and assume that it is differentiable with respect to $q$.\n",
    "* For simplicity, we shall assume that the $\\pi_Q$ is everywhere non-zero, so that $U$ is defined everywhere on $Q$. (If there exists a region on which $\\pi_Q = 0$ holds, then ergodicity might break. In my intuition, assuming that the region $\\left\\{ q \\in \\mathbb{R}^d | \\pi_Q(q) > 0 \\right\\}$ is singly connected may suffices, but I have not verified it.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Introducing the momentum variable\n",
    "\n",
    "Let us introduce \n",
    "\n",
    "* an auxiliary variable, which shall be called \"momentum\", $p \\in \\mathbb{R}^d$, and\n",
    "* a probability distribution $\\pi_P(p) \\propto e^{-K(p)}$ over $\\mathbb{R}^d$, where $K$ is even in the sense that $K(p) = K(-p)$ holds for all $p \\in \\mathbb{R}^d$. (Later, we take $K(p) = \\frac{1}{2} p^T p$.) It is assumeed that $\\pi_P$ can be easily sampled. \n",
    "\n",
    "Let us define the Hamiltonian $H$ by $H(q,p) = K(p) + U(q)$.\n",
    "\n",
    "Under these definitions, consider sampling from the joint probability distribution $\\pi_{Q, P}(q, p) = \\pi_Q(q) \\pi_P(p)$. \n",
    "It is clear that marginalizing the distribution with respect to $p$ will immediately give us $\\pi_Q$, our target distribution. Put differently, if we sample from the joint distribution and simply dispose $p$ components, then we get samples of $q$ which follows $\\pi_Q$.\n",
    "\n",
    "Also, it should be noted that $\\pi_{Q, P}(q, p) \\propto \\exp[-H(q, p)] =: \\tilde{\\pi}_{Q, P}(q, p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Recap of Metropolis-Hastings algorithm\n",
    "\n",
    "The idea of HMC is to use a deterministic dynamics to propose the next point in Metropolis-Hastings algorithm.\n",
    "Thus, here we quickly go through Metropolis-Hastings algorithm applied to the current problem.\n",
    "\n",
    "In the Metroopolis-Hastings algorithm, a single update step (which shall be called Metropolis-Hastings update) proceeds as follows (denote the current point by $(q_{\\rm current}, p_{\\rm current})$):  \n",
    "1. a point $(q_{\\rm tmp}, p_{\\rm tmp})$ is proposed according to a given proposal distribution $\\rho(q_{\\rm tmp}, p_{\\rm tmp} | q_{\\rm current}, p_{\\rm current})$.\n",
    "2. The next point $(q_{\\rm next}, p_{\\rm next})$ is determined by\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    (q_{\\rm next}, p_{\\rm next}) = \\begin{cases}\n",
    "        (q_{\\rm tmp}, p_{\\rm tmp}) &  (\\mbox{ with probability  } A((q_{\\rm tmp}, p_{\\rm tmp}), (q_{\\rm current}, p_{\\rm current} )) \\ )\\\\\n",
    "        (q_{\\rm current}, p_{\\rm current}) & (\\mbox{ with probability } 1 - A((q_{\\rm tmp}, p_{\\rm tmp}), (q_{\\rm current}, p_{\\rm current}) ) \\ )\n",
    "    \\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    A((q', p')| (q, p) ) := \\min \\left( 1, \\frac{\\tilde{\\pi}_{Q, P}(q', p')}{\\tilde{\\pi}_{Q, P}(q, p)} \\cdot \\frac{\\rho(q, p| q', p')}{\\rho(q', p' | q, p)}  \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In the former case, we say the proposed point $(q_{\\rm tmp}, p_{\\rm tmp})$ is accepted, while in the latter case it is said to be rejected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Metropolis-Hastings update with deterministic transitions\n",
    "\n",
    "Let us consider a deterministic transition defined by $f : \\mathbb{R}^d \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}^d \\times \\mathbb{R}^d $ as our proposal distribution:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\rho(q, p | q', p') = \\delta((q, p) - f(q', p')), \n",
    "\\end{align}\n",
    "$$\n",
    "where $\\delta$ stands for the delta fucnction. (NOTE : Here all the mathematical subtleties related to the delta function are neglected.)\n",
    "\n",
    "Assuming\n",
    "1. $f$ is invertible and $f^{-1} = f$, and\n",
    "2. $f$ has unit Jacobian, \n",
    "\n",
    "it can be shown that, \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    A((q', p')| (q, p) ) := \\min \\left( 1, \\frac{\\tilde{\\pi}_{Q, P}(q', p')}{\\tilde{\\pi}_{Q, P}(q, p)}   \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "holds(Again, I have not verified it in mathematically rigorous way.) \n",
    "\n",
    "Thus, if we can find a mapping $f$ that satisfies the properties shown above, we can use it to propose candidate points,  without being bothered by the ratio of proposal distribution. Also, if $f$ approximately conserves $\\tilde{\\pi}(q, p)$, then we can realize a low rejection rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Hamiltonian dynamics\n",
    "\n",
    "It turns out that Hamiltonian dynamics defined by \n",
    "$$\n",
    "\\begin{align}\n",
    "    \\frac{dq(t)}{dt} = \\left. \\frac{\\partial H(q, p)}{\\partial p} \\right|_{q=q(t), p=p(t)} \\\\\n",
    "    \\frac{dp(t)}{dt} = - \\left. \\frac{\\partial H(q, p)}{\\partial q}\\right|_{q=q(t), p=p(t)} \n",
    "\\end{align}\n",
    "$$\n",
    "fits perfectly with our purpose. Here, it should be understood as follows: starting from an arbitrarily chosen current point, denoted by  $(q_0, p_0)$, follow the time evolution defined by the differential equation for an arbitrary time interval, say, $s$, which gives us a point $(q(s), p(s))$. This mapping from $(q_0, p_0)$ to $(q(s), p(s))$ is expressed as $T_s$.\n",
    "\n",
    "The mapping $R \\circ T_s$, where $R$ stands for momentum inversion $R : (q, p) \\mapsto (q, -p)$, satisfies the following properties: \n",
    "1. Both $R$ and $T_s$ have unit Jacobian, and hence $R \\circ T_s$ also has unit Jacobian.\n",
    "2. $(R \\circ T_s)^{-1} = R \\circ T_s$ \n",
    "3. Both $R$ and $T_s$ conserves the value of Hamiltonian, and hence $H((R \\circ T_s)(q,p)) = H(q, p)$\n",
    "\n",
    "Thus, with this mapping, we can use the formula shown in the end of the previous section to perform Metropolis-Hastings update.\n",
    "However, there remain two problems:\n",
    "\n",
    "1. The mapping $T_s$ cannot be obtained exactly, and we must resort to numerical integration. \n",
    "2. Because $T_s$ conserves the value of $H$, it breaks ergodicity. (Its numerically approximated version may break the exact conservation, but if $H$ changes very slowly, then convergence toward stationary distribution can also be slow.) \n",
    "\n",
    "The latter problem is solved by interleaving the Metropolis-Hastings update (by Hamiltonian dynamics) with sampling the momentum $p$ from $\\pi_P$. It can be easily shown that this update leaves the probability distribution $\\pi_{Q, P}$ invariant.\n",
    "\n",
    "As to the former problem, we shall see in the next subsection how to integrate the differential equation numerically while exactly maintaining some desirable properties of the original Hamiltonian dynamics. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Leapfrog method\n",
    "\n",
    "Let us define $f_{\\delta} : \\mathbb{R}^d \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}^d \\times \\mathbb{R}^d$, $g_{\\delta} : \\mathbb{R}^d \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}^d \\times \\mathbb{R}^d$ and $h_{\\delta} : \\mathbb{R}^d \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}^d \\times \\mathbb{R}^d$ for $\\delta \\in \\mathbb{R}$ by \n",
    "$$\n",
    "\\begin{align}\n",
    "    f_{\\delta}\\left(\n",
    "        \\begin{array}{c}\n",
    "            q \\\\\n",
    "            p\n",
    "        \\end{array}\n",
    "    \\right)\n",
    "    = \\left(\n",
    "        \\begin{array}{c}\n",
    "            q \\\\\n",
    "            p - \\frac{\\delta}{2} \\frac{\\partial U}{\\partial q}\n",
    "        \\end{array}\n",
    "    \\right), \\\n",
    "    g_{\\delta}\\left(\n",
    "        \\begin{array}{c}\n",
    "            q \\\\\n",
    "            p\n",
    "        \\end{array}\n",
    "    \\right)\n",
    "    = \\left(\n",
    "        \\begin{array}{c}\n",
    "            q + \\delta \\frac{\\partial K}{\\partial p} \\\\\n",
    "            p\n",
    "        \\end{array}\n",
    "    \\right), \\\n",
    "    h_{\\delta} = f_{\\delta} \\circ g_{\\delta} \\circ f_{\\delta}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Let us denote a discretized time step by $\\varepsilon > 0$. \n",
    "Then, a single update of leapfrog method can be expressed by $h_{\\varepsilon}$. ($f_{\\varepsilon}$ corresponds to update (11.64) and (11.66) of PRML, while $g_{\\varepsilon}$ corresponds to update (11.65).). \n",
    "\n",
    "Assuming that we want to integrate the equation of motion over time interval $\\varepsilon L$, with $L \\in \\mathbb{N}$, the approximate dynamics can be expressed by $h_{\\varepsilon}^{L}$.\n",
    "\n",
    "It can be shown that \n",
    "1. $h_{\\varepsilon}$ and $h_{\\varepsilon}^{L}$ have unit Jacobian, and that\n",
    "2. $(R \\circ h_{\\varepsilon}^{L})^{-1} = R \\circ h_{\\varepsilon}^{L}$\n",
    "\n",
    "Thus, instead of $R \\circ T_s$, we can use $R \\circ h_{\\varepsilon}^{L}$ for the Metropolis-Hastings update. It should be noted, however, that now the value of Hamiltonian conserves only approximately, resulting in non-zero rejection probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 HMC algorithm\n",
    "\n",
    "With everything described so far in mind, a HMC update consists of the following two steps: \n",
    "\n",
    "NOTE : this algorithm is from Neal \"MCMC using Hamiltonian dynamics\" https://arxiv.org/abs/1206.1901\n",
    "\n",
    "input : $q_{\\rm current}, p_{\\rm current}$\n",
    "\n",
    "1. $p_{\\rm current} \\leftarrow$ value randomly sampled from $\\pi_P$\n",
    "2. Sample $(q,p)$ by Hamiltonian dynamics as follows:\n",
    "    1. $(q_{\\rm tmp}, p_{\\rm tmp}) \\leftarrow h_{\\varepsilon}^{L} (q_{\\rm current}, p_{\\rm current}) $, i.e., the point obtained by leapfrog update starting from $(q_{\\rm current}, p_{\\rm current})$, with step size $\\varepsilon$ and the number of steps $L$.\n",
    "    2. $p_{\\rm tmp} \\leftarrow  - p_{\\rm tmp}$\n",
    "    3. With probability $\\min\\left\\{ 1, \\exp\\left[ H(q_{\\rm current}, p_{\\rm current}) - H(q_{\\rm tmp}, p_{\\rm tmp}) \\right] \\right\\}$, accept $(q_{\\rm tmp}, p_{\\rm tmp})$, i.e., let $(q_{\\rm current}, p_{\\rm current}) \\leftarrow (q_{\\rm tmp}, p_{\\rm tmp})$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 From math to code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Leapfrog method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* leapfrog part : return trajectory. It can be run separately, so that Hamiltonian dynamics can be visualized in phase space (d=1 or d = 2).\n",
    "* sampling : should be capable of recording trajectories for both accepted and rejected point. visualization will be performed for d=2.\n",
    "* How HMC fails if epsilon and L are not properly chosen.\n",
    "* comparison with random walk in d=2 (visualization in q space)\n",
    "* comparison with random walk in d = 100 (reproduction of fig 6, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Experiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
